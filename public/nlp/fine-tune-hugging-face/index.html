<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: January 4, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  

  
  
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css" integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.d060e36f065b14306ff371728665eb02.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  

  <meta name="google-site-verification" content="Zv4l_ljWZhu4o0Z-kfZwQmuokpt40AvKXA78N8kynpc" />





<script async src="https://www.googletagmanager.com/gtag/js?id=G-55GQYC5GYC"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-55GQYC5GYC', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>




<script>
  (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','G-55GQYC5GYC');
</script>




















  
  
  






  <meta name="author" content="Arman Asgharpoor Golroudbari" />





  

<meta name="description" content="⇐ Natural Language Processing Fine Tune Pre-Trained Models with Hugging Face In the realm of Natural Language Processing (NLP), harnessing the capabilities of pre-trained models is a fundamental endeavor. These models, having already learned from vast amounts of text data, serve as valuable starting points for various NLP tasks." />



<link rel="alternate" hreflang="en-us" href="https://armanasq.github.io/nlp/fine-tune-hugging-face/" />
<link rel="canonical" href="https://armanasq.github.io/nlp/fine-tune-hugging-face/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@wowchemy" />
  <meta property="twitter:creator" content="@wowchemy" />
<meta property="twitter:image" content="https://armanasq.github.io/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_512x512_fill_lanczos_center_3.png" />
<meta property="og:site_name" content="" />
<meta property="og:url" content="https://armanasq.github.io/nlp/fine-tune-hugging-face/" />
<meta property="og:title" content="Fine Tune Pre-Trained Models with Hugging Face | " />
<meta property="og:description" content="⇐ Natural Language Processing Fine Tune Pre-Trained Models with Hugging Face In the realm of Natural Language Processing (NLP), harnessing the capabilities of pre-trained models is a fundamental endeavor. These models, having already learned from vast amounts of text data, serve as valuable starting points for various NLP tasks." /><meta property="og:image" content="https://armanasq.github.io/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2023-08-31T00:00:00&#43;00:00"
    />
  
  
    <meta property="article:modified_time" content="2023-08-31T00:00:00&#43;00:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://armanasq.github.io/nlp/fine-tune-hugging-face/"
  },
  "headline": "Fine Tune Pre-Trained Models with Hugging Face",
  
  "datePublished": "2023-08-31T00:00:00Z",
  "dateModified": "2023-08-31T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Arman Asgharpoor Golroudbari"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "",
    "logo": {
      "@type": "ImageObject",
      "url": "https://armanasq.github.io/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "⇐ Natural Language Processing Fine Tune Pre-Trained Models with Hugging Face In the realm of Natural Language Processing (NLP), harnessing the capabilities of pre-trained models is a fundamental endeavor. These models, having already learned from vast amounts of text data, serve as valuable starting points for various NLP tasks."
}
</script>

  

  




  
  
  

  
  

  


  
  <title>Fine Tune Pre-Trained Models with Hugging Face | </title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="20d7157ffbc39b33cbd25ed784085409" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/"></a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/"></a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/robotic"><span>Robotic</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#posts"><span>Posts</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#talks"><span>Talks</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/publication"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/certificates"><span>Certificates</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
            
            <li class="nav-item d-none d-lg-inline-flex">
              <a class="nav-link" href="mailto:a.asgharpoor1993@gmail.com" data-toggle="tooltip" data-placement="bottom" title="Drop me an email."  aria-label="Drop me an email.">
                <i class="fas fa-envelope" aria-hidden="true"></i>
              </a>
            </li>
          
            
            <li class="nav-item d-none d-lg-inline-flex">
              <a class="nav-link" href="https://github.com/armanasq" data-toggle="tooltip" data-placement="bottom" title="Follow Me on GitHub." target="_blank" rel="noopener" aria-label="Follow Me on GitHub.">
                <i class="fab fa-github" aria-hidden="true"></i>
              </a>
            </li>
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  













  

  
  
  
<div class="article-container pt-3">
  <h1>Fine Tune Pre-Trained Models with Hugging Face</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Aug 31, 2023
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    8 min read
  </span>
  

  
  
  
  

  
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      <p><a href="/nlp/">⇐ Natural Language Processing</a>
<img src="/hf-logo-with-title.png" alt="ROS" style="width:100%;display: block;
margin-left: auto;
margin-right: auto; margin-top:0px auto" ></p>
</div>
<h1 id="fine-tune-pre-trained-models-with-hugging-face">Fine Tune Pre-Trained Models with Hugging Face</h1>
<p>In the realm of Natural Language Processing (NLP), harnessing the capabilities of pre-trained models is a fundamental endeavor. These models, having already learned from vast amounts of text data, serve as valuable starting points for various NLP tasks. Hugging Face, a library widely embraced by NLP practitioners, simplifies the process of fine-tuning pre-trained models to suit specific applications.</p>
<p>Fine-tuning entails refining a pre-trained model by training it further on domain-specific data. This process allows the model to adapt and excel in tasks like text classification, sentiment analysis, and more. With its user-friendly interfaces and comprehensive functionalities, Hugging Face empowers us to effectively fine-tune these models, bridging the gap between general language understanding and specific tasks.</p>
<p>This tutorial delves into the pragmatic intricacies of fine-tuning pre-trained models using Hugging Face. We will explore the nuances of preparing datasets, navigating hyperparameters, visualizing training progress, and employing advanced training techniques. By the end of this tutorial, you&rsquo;ll be well-equipped to unlock the full potential of pre-trained models for your NLP undertakings.</p>
<h2 id="section-1-prepare-your-dataset">Section 1: Prepare Your Dataset</h2>
<h3 id="data-exploration">Data Exploration</h3>
<p>Before delving into preprocessing, it&rsquo;s essential to understand your dataset&rsquo;s structure. For instance, let&rsquo;s explore the Yelp Reviews dataset, which consists of reviews and associated ratings. Understanding your data is crucial, so let&rsquo;s begin by gaining insights into the dataset&rsquo;s dimensions:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&#34;yelp_review_full&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Display the number of training and test examples</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Number of training examples:&#34;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Number of test examples:&#34;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&#34;test&#34;</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Print a few training examples</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Example&#34;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&#34;:&#34;</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&#34;text&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Rating:&#34;</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s2">&#34;label&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;----------&#34;</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">Number of training examples: <span class="m">650000</span>
</span></span><span class="line"><span class="cl">Number of <span class="nb">test</span> examples: <span class="m">50000</span>
</span></span><span class="line"><span class="cl">Example <span class="m">0</span> : dr. goldberg offers everything i look <span class="k">for</span> in a general practitioner.  he<span class="s1">&#39;s nice and easy to talk to without being patronizing; he&#39;</span>s always on <span class="nb">time</span> in seeing his patients<span class="p">;</span> he<span class="s1">&#39;s affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i&#39;</span>m sitting here trying to think of any complaints i have about him, but i<span class="s1">&#39;m really drawing a blank.
</span></span></span><span class="line"><span class="cl"><span class="s1">Rating: 4
</span></span></span><span class="line"><span class="cl"><span class="s1">----------
</span></span></span><span class="line"><span class="cl"><span class="s1">Example 1 : Unfortunately, the frustration of being Dr. Goldberg&#39;</span>s patient is a repeat of the experience I<span class="s1">&#39;ve had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don&#39;</span>t get it.  You have office workers, you have patients with medical needs, why isn<span class="s1">&#39;t anyone answering the phone?  It&#39;</span>s incomprehensible and not work the aggravation.  It<span class="s1">&#39;s with regret that I feel that I have to give Dr. Goldberg 2 stars.
</span></span></span><span class="line"><span class="cl"><span class="s1">Rating: 1
</span></span></span><span class="line"><span class="cl"><span class="s1">----------
</span></span></span><span class="line"><span class="cl"><span class="s1">Example 2 : Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He&#39;</span>s been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn<span class="err">&#39;</span>t judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.
</span></span><span class="line"><span class="cl">Rating: <span class="m">3</span>
</span></span><span class="line"><span class="cl">----------
</span></span></code></pre></div><p>This exploration gives you a bird&rsquo;s-eye view of your dataset, aiding in identifying potential imbalances and understanding its distribution.</p>
<h3 id="tokenization-strategies">Tokenization Strategies</h3>
<p>Tokenization lies at the core of NLP tasks, where text input is transformed into a sequence of tokens understandable by machine learning models. Hugging Face provides a versatile Tokenizer class that simplifies this crucial step. Tokenizers are available for various models and come in two flavors: a full Python implementation and a &ldquo;Fast&rdquo; implementation based on the Rust library, which offers improved performance, especially for batched tokenization.</p>
<h4 id="preparing-inputs">Preparing Inputs</h4>
<p>The main classes for tokenization are <code>PreTrainedTokenizer</code> and <code>PreTrainedTokenizerFast</code>, which are base classes for all tokenizers. These classes provide common methods for encoding string inputs into model-ready inputs. They handle tokenizing (splitting text into sub-word token strings), converting token strings to IDs and vice versa, and encoding/decoding (tokenizing and converting to integers). Additionally, they facilitate the management of special tokens like mask, beginning-of-sentence, etc., ensuring they are not split during tokenization.</p>
<h4 id="special-tokens">Special Tokens</h4>
<p>Hugging Face tokenizers offer attributes for important special tokens like <code>[MASK]</code>, <code>[CLS]</code>, <code>[SEP]</code>, and more. You can easily add new special tokens to the vocabulary without altering the underlying tokenizer structure. These tokens are used for various purposes such as marking the start or end of sentences, padding sequences, and masking tokens for language modeling tasks.</p>
<h4 id="tokenizing-text">Tokenizing Text</h4>
<p>The <code>encode</code> method in the Tokenizer class is the key for tokenization. It takes the input text and tokenizes it, allowing for various options like adding special tokens, padding, truncation, and controlling the maximum length. For instance, by setting <code>add_special_tokens=True</code>, you ensure that the appropriate special tokens are added to the beginning and end of the token sequence. Truncation and padding can be managed using parameters like <code>max_length</code>, <code>padding</code>, and <code>truncation</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">text</span> <span class="o">=</span> <span class="s2">&#34;Hello, how are you?&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&#34;bert-base-uncased&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="o">[</span>101, 7592, 1010, 2129, 2024, 2017, 1029, 102<span class="o">]</span>
</span></span></code></pre></div><h4 id="decoding-tokens">Decoding Tokens</h4>
<p>The <code>decode</code> method performs the inverse operation of tokenization. It takes a sequence of token IDs and converts it back to a human-readable text string. Special tokens can be skipped during decoding using the <code>skip_special_tokens</code> parameter.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">decoded_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">decoded_text</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="batch-encoding">Batch Encoding</h4>
<p>For efficiency in processing multiple inputs, the <code>batch_encode_plus</code> method tokenizes a batch of sequences at once. It returns a <code>BatchEncoding</code> object that contains various model inputs like <code>input_ids</code>, <code>attention_mask</code>, and more.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;Hello, how are you?&#34;</span><span class="p">,</span> <span class="s2">&#34;I&#39;m doing well, thank you!&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">batch_encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">batch_encoding</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">batch_encoding</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="custom-tokenization">Custom Tokenization</h4>
<p>Hugging Face tokenizers also support custom tokenization functions. If your input is already tokenized (e.g., for Named Entity Recognition), you can set <code>is_split_into_words=True</code> and tokenize accordingly.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;Hello&#34;</span><span class="p">,</span> <span class="s2">&#34;,&#34;</span><span class="p">,</span> <span class="s2">&#34;how&#34;</span><span class="p">,</span> <span class="s2">&#34;are&#34;</span><span class="p">,</span> <span class="s2">&#34;you&#34;</span><span class="p">,</span> <span class="s2">&#34;?&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">is_split_into_words</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
</span></span></code></pre></div><p>Hugging Face&rsquo;s Tokenizer class simplifies this process by providing an array of methods and options to tokenize, encode, decode, and handle special tokens effectively. By understanding and utilizing these strategies, you can seamlessly integrate tokenization into your NLP workflows.</p>
<h2 id="section-2-fine-tune-a-pretrained-model-with-the-trainer-class">Section 2: Fine-Tune a Pretrained Model with the Trainer Class</h2>
<p>Get ready to dive deeper into training using the powerful <code>Trainer</code> class. By exploring hyperparameter tuning, visualization options, and advanced training techniques, you&rsquo;ll wield Hugging Face&rsquo;s prowess to the fullest.</p>
<h3 id="hyperparameter-tuning">Hyperparameter Tuning</h3>
<p>Mastering hyperparameters is a cornerstone of model training. Uncover essential hyperparameters within the <code>TrainingArguments</code> class:</p>
<ul>
<li><code>learning_rate</code>: Controls optimization&rsquo;s step size.</li>
<li><code>num_train_epochs</code>: Specifies training epochs.</li>
<li><code>per_device_train_batch_size</code>: Sets batch size during training.</li>
</ul>
<p>Discover the art of hyperparameter tuning by experimenting with different values for optimal performance.</p>
<h3 id="visualizing-training-progress">Visualizing Training Progress</h3>
<p>Real-time training visualization empowers your progress tracking. Integrate TensorBoard seamlessly into the <code>Trainer</code> class for dynamic insights:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&#34;./fine-tuned-model&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&#34;epoch&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">logging_dir</span><span class="o">=</span><span class="s2">&#34;./logs&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">logging_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">report_to</span><span class="o">=</span><span class="s2">&#34;tensorboard&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_dataset</span><span class="o">=</span><span class="n">small_train_dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">small_eval_dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p>Visualizing training progress using TensorBoard enhances your ability to track metrics, identify trends, and make informed decisions.</p>
<h3 id="advanced-training-techniques">Advanced Training Techniques</h3>
<p>Elevate your training beyond the basics by exploring advanced techniques like gradient accumulation, mixed precision training, and learning rate schedules:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Experiment with gradient accumulation and mixed precision training</span>
</span></span><span class="line"><span class="cl"><span class="n">training_args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">4</span>
</span></span><span class="line"><span class="cl"><span class="n">training_args</span><span class="o">.</span><span class="n">fp16</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Implement a learning rate schedule</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">get_linear_schedule_with_warmup</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">5</span><span class="n">e</span><span class="o">-</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_linear_schedule_with_warmup</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_training_steps</span><span class="o">=</span><span class="n">num_train_steps</span><span class="p">)</span>
</span></span></code></pre></div><p>Understanding and implementing these advanced techniques empower you to achieve faster convergence and better results in complex training scenarios.</p>
<h2 id="section-3-fine-tuning-a-pretrained-model-in-native-pytorch">Section 3: Fine-Tuning a Pretrained Model in Native PyTorch</h2>
<p>Delve into the heart of model training by exploring native PyTorch techniques. By mastering gradient clipping, learning rate schedulers, and custom evaluation functions, you&rsquo;ll deepen your understanding of underlying mechanisms.</p>
<h3 id="gradient-clipping">Gradient Clipping</h3>
<p>Prevent gradient explosions with precision. Implement gradient clipping to scale gradients if their norms surpass a predefined threshold:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.nn.utils</span> <span class="kn">import</span> <span class="n">clip_grad_norm_</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mf">1.0</span>
</span></span><span class="line"><span class="cl"><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_grad_norm</span><span class="p">)</span>
</span></span></code></pre></div><p>Implementing gradient clipping safeguards your training from numerical instability and ensures smoother convergence.</p>
<h3 id="learning-rate-schedulers">Learning Rate Schedulers</h3>
<p>Fine-tune your model&rsquo;s learning rate dynamically. PyTorch offers a suite of learning rate schedulers, including StepLR, ReduceLROnPlateau, and CosineAnnealingLR:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">StepLR</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span></code></pre></div><p>Adapting learning rates using these schedulers optimizes model performance and accelerates convergence.</p>
<h3 id="custom-evaluation-functions">Custom Evaluation Functions</h3>
<p>Elevate your evaluation metrics by incorporating precision, recall, and F1-score alongside accuracy:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_fscore_support</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">compute_custom_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">logits</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
</span></span><span class="line"><span class="cl">    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&#34;weighted&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="p">{</span><span class="s2">&#34;accuracy&#34;</span><span class="p">:</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="s2">&#34;precision&#34;</span><span class="p">:</span> <span class="n">precision</span><span class="p">,</span> <span class="s2">&#34;recall&#34;</span><span class="p">:</span> <span class="n">recall</span><span class="p">,</span> <span class="s2">&#34;f1&#34;</span><span class="p">:</span> <span class="n">f1</span><span class="p">}</span>
</span></span></code></pre></div><p>Crafting custom evaluation functions enables you to assess model performance with a nuanced perspective.</p>
<h2 id="section-4-additional-resources">Section 4: Additional Resources</h2>
<p>As you&rsquo;ve delved deep into Hugging Face&rsquo;s capabilities, keep expanding your horizons with these additional resources:</p>
<ul>
<li><a href="https://huggingface.co/models" target="_blank" rel="noopener">Hugging Face Model Hub</a>: Access a treasure trove of pretrained models for diverse NLP tasks.</li>
<li><a href="https://huggingface.co/docs/transformers/" target="_blank" rel="noopener">Transformers Documentation</a>: Journey into the library&rsquo;s comprehensive documentation for advanced features and use cases.</li>
<li><a href="https://discuss.huggingface.co/" target="_blank" rel="noopener">Hugging Face Forum</a>: Join a vibrant community to share, learn, and engage with fellow NLP enthusiasts.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Congratulations! You&rsquo;ve completed an extensive journey into the world of advanced NLP using the Hugging Face library. By mastering data preparation, advanced training techniques, and native PyTorch approaches, you&rsquo;re equipped to tackle complex NLP challenges with confidence. Remember, continuous learning and exploration in this dynamic field will lead you to ever greater heights. Happy fine-tuning and experimenting!</p>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/natural-language-processing/">Natural Language Processing</a>
  
  <a class="badge badge-light" href="/tag/nlp/">NLP</a>
  
  <a class="badge badge-light" href="/tag/tutorial/">Tutorial</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Farmanasq.github.io%2Fnlp%2Ffine-tune-hugging-face%2F&amp;text=Fine&#43;Tune&#43;Pre-Trained&#43;Models&#43;with&#43;Hugging&#43;Face" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Farmanasq.github.io%2Fnlp%2Ffine-tune-hugging-face%2F&amp;t=Fine&#43;Tune&#43;Pre-Trained&#43;Models&#43;with&#43;Hugging&#43;Face" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=Fine%20Tune%20Pre-Trained%20Models%20with%20Hugging%20Face&amp;body=https%3A%2F%2Farmanasq.github.io%2Fnlp%2Ffine-tune-hugging-face%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Farmanasq.github.io%2Fnlp%2Ffine-tune-hugging-face%2F&amp;title=Fine&#43;Tune&#43;Pre-Trained&#43;Models&#43;with&#43;Hugging&#43;Face" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=Fine&#43;Tune&#43;Pre-Trained&#43;Models&#43;with&#43;Hugging&#43;Face%20https%3A%2F%2Farmanasq.github.io%2Fnlp%2Ffine-tune-hugging-face%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Farmanasq.github.io%2Fnlp%2Ffine-tune-hugging-face%2F&amp;title=Fine&#43;Tune&#43;Pre-Trained&#43;Models&#43;with&#43;Hugging&#43;Face" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://armanasq.github.io/"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu423262b037e945bf3d00a3d75617f940_247637_270x270_fill_q75_lanczos_center.jpeg" alt="Arman Asgharpoor Golroudbari"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://armanasq.github.io/">Arman Asgharpoor Golroudbari</a></h5>
      <h6 class="card-subtitle">Space-AI Researcher</h6>
      <p class="card-text">My research interests revolve around planetary rovers and spacecraft vision-based navigation.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-comment-alt"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:a.asgharpoor1993@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=IlAgF9UAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/armanasq" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://linkedin.com/in/asgharpoor" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://orcid.org/my-orcid?orcid=0000-0001-6271-4533" target="_blank" rel="noopener">
        <i class="ai ai-orcid"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://www.webofscience.com/wos/author/record/IAN-3152-2023" target="_blank" rel="noopener">
        <i class="ai ai-publons"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://researchgate.net/profile/Arman_Asgharpoor" target="_blank" rel="noopener">
        <i class="ai ai-researchgate"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/uploads/cv.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>









  
  
  

  

  
  <section id="comments">
    
  
  <script src="https://giscus.app/client.js"
          data-repo="Armanasq/Armanasq.github.io"
          data-repo-id="R_kgDOJi13ZQ"
          data-category="[ENTER CATEGORY NAME HERE]"
          data-category-id="[ENTER CATEGORY ID HERE]"
          data-mapping="pathname"
          data-strict="0"
          data-reactions-enabled="1"
          data-emit-metadata="0"
          data-input-position="top"
          data-theme="preferred_color_scheme"
          data-lang="en"
          data-loading="lazy"
          crossorigin="anonymous"
          async>
  </script>


  </section>
  










  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2024 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js"></script>




  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.85070d5fe00d43eaedff44310b81dc2c.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>













  
    
      
      <!DOCTYPE html>
<html>
<head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-55GQYC5GYC"></script>

<style>
  .myImg {
    border-radius: 5px;
    cursor: pointer;
    transition: 0.3s;
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  .myImg:hover {
    opacity: 0.7;
    cursor: pointer;
  }

   
  .modal-img {
    display: none;  
    position: fixed;  
    z-index: 1;  
    padding-top: 150px;  
    left: 0;
    top: 0px;
    width: 100%;  
    height: 100%;  
    overflow: visible;  
    background-color: rgb(0, 0, 0);  
    background-color: rgba(0, 0, 0, 0.6);  
    margin-left: auto;
    margin-right: auto;
  }

   
  .modal-content {
    display: block;
    margin-left: auto;
    margin-right: auto;
    max-width: 80%;
    max-height: 80%;

  }

   
  #caption {
    margin-left: auto;
    margin-right: auto;
    width: 80%;
    max-width: 700px;
    text-align: center;
    padding: 10px 0;

  }

   
  .modal-content,
  #caption {
    -webkit-animation-name: zoom;
    -webkit-animation-duration: 0.6s;
    animation-name: zoom;
    animation-duration: 0.6s;
    margin-left: auto;
    margin-right: auto;
  }

  @-webkit-keyframes zoom {
    from {
      -webkit-transform: scale(0);
    }
    to {
      -webkit-transform: scale(1);
    }
  }

  @keyframes zoom {
    from {
      transform: scale(0);
    }
    to {
      transform: scale(1);
    }
  }

   
  
 .modal-close {
    position: absolute;
    top: -55px;
    right: 0;
    font-size: 40px;
    font-weight: bold;
    transition: 0.3s;
    cursor: pointer;
  }

  .modal-close:hover,
  .modal-close:focus {
    color: #bbb;
    text-decoration: none;
  }

   
  @media only screen and (max-width: 900px) {
    .modal-content {
      width: 90%;
    }
  }

  .test:hover {
    scale: 1.2;
  }







  .navbar-nav {
    font-size:20px;
    font-family: Merriweather,sans-serif;
  }

  .robotic-section-container {
    display: flex;
    flex-wrap: wrap;
    justify-content: space-between;
    max-width: 1200px;
    margin: 0 auto;
  }
  
  .robotic-section {
    flex-basis: calc(30.33% - 12px);
    margin: 10px;
    background-color: #fff;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    border-radius: 8px;
    transition: box-shadow 0.3s ease-in-out;
    overflow: hidden;
  }
  
  .robotic-section:hover {
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
  }
  
  .robotic-section-content {
    text-align: center;
    padding: 20px;
    display: flex;
    flex-direction: column;
    justify-content: space-between;
    height: 100%;
  }
  
  .robotic-section-content .image-placeholder {
    width: 300px;
    height: 300px;
    margin: 0 auto;
    display: flex;
    align-items: center;
    justify-content: center;
    background-color: #f1f1f1;
  }
  
  .robotic-section-content .image-placeholder img {
    max-width: 100%;
    max-height: 100%;
    object-fit: contain;
  }
  
  .robotic-section-content-h2 {
    margin-top: 10px;
    font-size: 1.rem;
    font-weight: bold;
    color: #333;
  }
  
  .robotic-section-content-h2 :hover{
    font-size: 10px
  }
  .robotic-section-content-h2 {
    margin-top: 10px;
    color: #777;
    font-size: 1.2rem;
  }
  
  .robotic-section-content .text-placeholder {
    height: 80px;
    background-color: #f1f1f1;
  }
  
  .robotic-section-content a {
    display: inline-block;
    margin-top: 20px;
    padding: 10px 20px;
    background-color: #FF4081;
    color: #fff;
    text-decoration: none;
    border-radius: 4px;
    font-weight: bold;
    transition: background-color 0.3s ease-in-out;
  }
  
  .robotic-section-content a:hover {
    background-color: #E91E63;
  }
  
   
  @media (max-width: 768px) {
    .robotic-section {
      flex-basis: calc(50% - 40px);
    }
  }
  
   
  @media (max-width: 480px) {
    .robotic-section {
      flex-basis: 100%;
    }
  }
</style>
</head>
<body>

<div id="myModal" class="modal-img">
  <div class="modal-content">
    <span class="modal-close">&times;</span>
    <img id="img01" style="margin-left: auto; margin-right: auto;">
    <div id="caption"></div>
  </div>
</div>




<script>
    
    var modal = document.getElementById("myModal");
    
    
    var images = document.querySelectorAll("img.myImg");
    
    
    var modalImg = document.getElementById("img01");
    var captionText = document.getElementById("caption");
    
    
    for (var i = 0; i < images.length; i++) {
      
      images[i].setAttribute("data-src", images[i].src);
      
      images[i].addEventListener("click", function() {
        
        modalImg.src = this.getAttribute("data-src");
        captionText.innerHTML = this.alt;
        
        modal.style.display = "block";
      });
    }
    
    
    var modalClose = document.querySelector(".modal-content .modal-close");
    
    
    modalClose.onclick = function() {
      modal.style.display = "none";
    };
    
















    
    </script>
    
    </body>
    </html>
      
    
  






</body>
</html>

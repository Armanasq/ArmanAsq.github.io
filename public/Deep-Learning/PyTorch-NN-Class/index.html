<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: January 4, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  

  
  
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css" integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.d060e36f065b14306ff371728665eb02.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  

  <meta name="google-site-verification" content="Zv4l_ljWZhu4o0Z-kfZwQmuokpt40AvKXA78N8kynpc" />





<script async src="https://www.googletagmanager.com/gtag/js?id=G-55GQYC5GYC"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-55GQYC5GYC', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>




<script>
  (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','G-55GQYC5GYC');
</script>




















  
  
  






  <meta name="author" content="Arman Asgharpoor Golroudbari" />





  

<meta name="description" content="A tutorial on mastering Neural Network Class in PyTorch! ." />



<link rel="alternate" hreflang="en-us" href="https://armanasq.github.io/Deep-Learning/PyTorch-NN-Class/" />
<link rel="canonical" href="https://armanasq.github.io/Deep-Learning/PyTorch-NN-Class/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@wowchemy" />
  <meta property="twitter:creator" content="@wowchemy" />
<meta property="twitter:image" content="https://armanasq.github.io/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_512x512_fill_lanczos_center_3.png" />
<meta property="og:site_name" content="" />
<meta property="og:url" content="https://armanasq.github.io/Deep-Learning/PyTorch-NN-Class/" />
<meta property="og:title" content="PyTorch Tutorial: Implementing a Neural Network Class | " />
<meta property="og:description" content="A tutorial on mastering Neural Network Class in PyTorch! ." /><meta property="og:image" content="https://armanasq.github.io/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2023-06-05T00:00:00&#43;00:00"
    />
  
  
    <meta property="article:modified_time" content="2023-06-05T00:00:00&#43;00:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://armanasq.github.io/Deep-Learning/PyTorch-NN-Class/"
  },
  "headline": "PyTorch Tutorial: Implementing a Neural Network Class",
  
  "datePublished": "2023-06-05T00:00:00Z",
  "dateModified": "2023-06-05T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Arman Asgharpoor Golroudbari"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "",
    "logo": {
      "@type": "ImageObject",
      "url": "https://armanasq.github.io/media/icon_hu3a1b1aacf1bb12033635935a8f8a9863_117561_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "A tutorial on mastering Neural Network Class in PyTorch! ."
}
</script>

  

  




  
  
  

  
  

  


  
  <title>PyTorch Tutorial: Implementing a Neural Network Class | </title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="e90f46f6871bf7c88842f460b781afba" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/"></a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/"></a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/robotic"><span>Robotic</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#posts"><span>Posts</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#talks"><span>Talks</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/publication"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/certificates"><span>Certificates</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
            
            <li class="nav-item d-none d-lg-inline-flex">
              <a class="nav-link" href="mailto:a.asgharpoor1993@gmail.com" data-toggle="tooltip" data-placement="bottom" title="Drop me an email."  aria-label="Drop me an email.">
                <i class="fas fa-envelope" aria-hidden="true"></i>
              </a>
            </li>
          
            
            <li class="nav-item d-none d-lg-inline-flex">
              <a class="nav-link" href="https://github.com/armanasq" data-toggle="tooltip" data-placement="bottom" title="Follow Me on GitHub." target="_blank" rel="noopener" aria-label="Follow Me on GitHub.">
                <i class="fab fa-github" aria-hidden="true"></i>
              </a>
            </li>
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  













  

  
  
  
<div class="article-container pt-3">
  <h1>PyTorch Tutorial: Implementing a Neural Network Class</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Jun 5, 2023
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    13 min read
  </span>
  

  
  
  
  

  
  

</div>

    




<div class="btn-links mb-3">
  
  








  






  
  
    
  
<a class="btn btn-outline-primary btn-page-header" href="https://colab.research.google.com/drive/1B0bRq3XpbDGOuVRi8q3ycNiR_gatfBH8?usp=sharing" target="_blank" rel="noopener">
  Code
</a>













  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header" href="https://github.com/Armanasq/Deep-Learning-Tutorial/blob/main/PyTorch/Deep_Neural_Network_Implementation_Using_PyTorch.ipynb" target="_blank" rel="noopener">
    <i class="fab fa-github mr-1"></i>Project Code</a>


</div>


  
</div>



  <div class="article-container">

    <div class="article-style">
      <div style='background-color: rgba(225,225,225,0.48); padding: 10px; border-radius:15px;'>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/PyTorch/pytorch.png" alt="png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
</div>
<h1 id="comprehensive-pytorch-tutorial-implementing-a-neural-network-class">Comprehensive PyTorch Tutorial: Implementing a Neural Network Class</h1>
<p>🎉 Welcome to this tutorial on implementing a Neural Network class using PyTorch! 🎉</p>
<p>In this tutorial, we will focus on building a Neural Network class in PyTorch and go through each step in detail, explaining every part of the Neural Network class, so you can understand the underlying concepts thoroughly.</p>
<ul>
<li><a href="#comprehensive-pytorch-tutorial-implementing-a-neural-network-class">Comprehensive PyTorch Tutorial: Implementing a Neural Network Class</a>
<ul>
<li><a href="#1-introduction-to-neural-networks-">1. Introduction to Neural Networks 🧠</a>
<ul>
<li><a href="#11-the-neurons---building-blocks-of-a-neural-network">1.1 The Neurons - Building Blocks of a Neural Network</a></li>
<li><a href="#12-learning-superpowers-">1.2 Learning Superpowers 💪</a></li>
<li><a href="#13-building-a-neural-network-%ef%b8%8f">1.3 Building a Neural Network 🛠️</a></li>
<li><a href="#14-the-amazing-forward-pass-%ef%b8%8f">1.4 The Amazing Forward Pass 🏃‍♂️</a></li>
<li><a href="#15-learning-from-mistakes-">1.5 Learning from Mistakes 🧠⚡</a></li>
</ul>
</li>
<li><a href="#2-building-blocks-of-a-neural-network">2. Building Blocks of a Neural Network</a>
<ul>
<li><a href="#input-layer">Input Layer</a></li>
<li><a href="#hidden-layers">Hidden Layers</a></li>
<li><a href="#output-layer">Output Layer</a></li>
<li><a href="#3-defining-the-neural-network-model-class">3. Defining the Neural Network Model Class</a></li>
<li><a href="#31-parts-of-the-neural-network-model-class">3.1 Parts of the Neural Network Model Class</a>
<ul>
<li><a href="#311-the-constructor-method">3.1.1 The Constructor Method</a></li>
<li><a href="#312-the-forward-method">3.1.2 The Forward Method</a></li>
<li><a href="#313-the-input-layer">3.1.3 The Input Layer</a></li>
<li><a href="#314-the-hidden-layers">3.1.4 The Hidden Layers</a></li>
<li><a href="#315-the-output-layer">3.1.5 The Output Layer</a></li>
</ul>
</li>
<li><a href="#32-defining-the-neural-network-model-class-in-code">3.2 Defining the Neural Network Model Class in Code</a>
<ul>
<li><a href="#explanation">Explanation:</a></li>
</ul>
</li>
<li><a href="#33-summary">3.3 Summary</a></li>
</ul>
</li>
<li><a href="#4-implementing-forward-propagation">4. Implementing Forward Propagation</a></li>
<li><a href="#5-backpropagation-and-training">5. Backpropagation and Training</a></li>
<li><a href="#6-adding-activation-functions">6. Adding Activation Functions</a></li>
<li><a href="#7-customizing-loss-functions">7. Customizing Loss Functions</a></li>
<li><a href="#8-optimizers-for-training">8. Optimizers for Training</a></li>
<li><a href="#9-putting-it-all-together-example-usage">9. Putting It All Together: Example Usage</a></li>
<li><a href="#10-conclusion">10. Conclusion</a></li>
</ul>
</li>
</ul>
<p>Let&rsquo;s get started!</p>
<h2 id="1-introduction-to-neural-networks-">1. Introduction to Neural Networks 🧠</h2>
<div style='background-color: rgba(245,245,245,0.80); padding: 0px; border-radius:15px; margin-bottom: 15px; '>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img src="/PyTorch/nn.png" alt="png" loading="lazy" data-zoomable /></div>
  </div></figure>
</p>
<p><a style="color:rgb(0, 0, 250); padding-left: 10px; font-size: 12px" href="https://alexlenail.me/NN-SVG/">[Credit: Alex Lenail]</a>.</p>
</div>
<p>Neural Networks are fascinating and powerful models inspired by the intricate structure of the human brain. They have revolutionized the field of artificial intelligence and are at the core of many modern machine learning advancements. In this introduction, we will delve into the inner workings of Neural Networks, exploring their architecture, learning process, and applications.</p>
<h3 id="11-the-neurons---building-blocks-of-a-neural-network">1.1 The Neurons - Building Blocks of a Neural Network</h3>
<p>At the heart of a Neural Network are artificial neurons, also known as nodes. These neurons are analogous to the neurons in the human brain, and they are responsible for processing and transmitting information. Each neuron takes input from other neurons or external data, processes it using learnable parameters (weights and biases), and then produces an output. These outputs serve as inputs for the neurons in the next layer, creating a cascade of interconnected information flow.</p>
<h3 id="12-learning-superpowers-">1.2 Learning Superpowers 💪</h3>
<p>The learning process in Neural Networks is a marvel of computational intelligence. During training, the network learns from labeled examples to adjust its learnable parameters (weights and biases). This optimization process aims to minimize a predefined loss function that measures the difference between the predicted outputs and the true labels.</p>
<p>To achieve this, the network utilizes a powerful algorithm called backpropagation. During backpropagation, the network&rsquo;s performance on the training data is evaluated, and the gradients of the loss function with respect to the learnable parameters are calculated. These gradients indicate the direction and magnitude of adjustments needed to minimize the loss. The network then uses optimization algorithms, like stochastic gradient descent (SGD) or Adam, to update the parameters accordingly.</p>
<h3 id="13-building-a-neural-network-">1.3 Building a Neural Network 🛠️</h3>
<p>To construct a Neural Network, we first decide on its architecture. This includes determining the number of layers, the number of neurons in each layer, and the connections between them. The first layer is the input layer, which receives the raw input data. The last layer is the output layer, responsible for producing the final predictions or outcomes of the network.</p>
<p>In between the input and output layers, we have one or more hidden layers. These layers are the powerhouse of the network, as they perform the complex computations and feature extraction required for learning intricate patterns in the data. The number of hidden layers and the number of neurons in each layer are hyperparameters that depend on the problem&rsquo;s complexity and the size of the dataset.</p>
<h3 id="14-the-amazing-forward-pass-">1.4 The Amazing Forward Pass 🏃‍♂️</h3>
<p>Once we have our Neural Network architecture set up, it&rsquo;s time for the forward pass! During the forward pass, data flows through the network from the input layer to the output layer. At each neuron, the input data is multiplied by the corresponding weights, and biases are added to create a weighted sum. This sum is then passed through an activation function, like the popular Rectified Linear Unit (ReLU) or Sigmoid, to introduce non-linearity to the model.</p>
<p>The result of each neuron&rsquo;s computation becomes the input for the neurons in the next layer. This sequential computation through the layers enables the network to learn increasingly abstract and higher-level representations of the input data.</p>
<h3 id="15-learning-from-mistakes-">1.5 Learning from Mistakes 🧠⚡</h3>
<p>After the forward pass, the network compares its predictions with the true labels of the training data. The discrepancies between the predicted outputs and the true labels are quantified using a loss function, such as mean squared error or cross-entropy loss. The goal during training is to minimize this loss, effectively reducing the difference between the predicted and true values.</p>
<h2 id="2-building-blocks-of-a-neural-network">2. Building Blocks of a Neural Network</h2>
<p>A basic Neural Network consists of three main components:</p>
<h3 id="input-layer">Input Layer</h3>
<p>The input layer receives the data and passes it to the next layer. The number of neurons in this layer corresponds to the size of the input data.</p>
<h3 id="hidden-layers">Hidden Layers</h3>
<p>The hidden layers process the input data through a series of transformations. They learn to extract relevant features from the data, enabling the network to make accurate predictions.</p>
<h3 id="output-layer">Output Layer</h3>
<p>The output layer produces the final predictions or outputs of the model. The number of neurons in this layer is determined by the task (e.g., binary classification, multi-class classification, regression).</p>
<h3 id="3-defining-the-neural-network-model-class">3. Defining the Neural Network Model Class</h3>
<p>In this section, we will thoroughly explore the process of defining the Neural Network Model class in PyTorch. Understanding this fundamental step is crucial for building advanced neural networks for various machine learning tasks. We will discuss each component of the class in detail, explain their significance, and provide illustrative code examples to solidify our understanding.</p>
<h3 id="31-parts-of-the-neural-network-model-class">3.1 Parts of the Neural Network Model Class</h3>
<h4 id="311-the-constructor-method">3.1.1 The Constructor Method</h4>
<p>The constructor method (<code>__init__</code>) is the starting point for building our Neural Network Model class. It is called when an instance of the class is created and sets up the architecture of the neural network. This method allows us to define various parameters, such as the input size, hidden layer sizes, and output size, enabling us to customize the model based on the task at hand. The constructor is vital because it specifies the model&rsquo;s architecture and provides a way to set hyperparameters and other configurations.</p>
<h4 id="312-the-forward-method">3.1.2 The Forward Method</h4>
<p>The forward method is the heart of the Neural Network Model class. It defines how input data flows through the network to produce predictions. During the forward pass, data goes through each layer sequentially, and activation functions are applied to introduce non-linearity. This process allows the neural network to learn complex patterns and relationships from the input data. The forward method is essential for enabling efficient computation and automatic differentiation during backpropagation, which is the key to training the neural network.</p>
<h4 id="313-the-input-layer">3.1.3 The Input Layer</h4>
<p>The input layer of the neural network is the initial layer that receives the raw input data and connects it to the first hidden layer. The number of neurons in the input layer is determined by the size of the input data, which, in turn, defines the number of features or input dimensions. Each neuron in the input layer corresponds to one feature of the input data, and these neurons act as entry points to the neural network.</p>
<h4 id="314-the-hidden-layers">3.1.4 The Hidden Layers</h4>
<p>The hidden layers of the neural network are where the real computation and feature extraction occur. Each hidden layer contains multiple neurons (also known as nodes), and these neurons are fully connected to the neurons in the previous and subsequent layers. The hidden layers process the input data through a series of linear transformations followed by activation functions. These activations introduce non-linearity to the model, enabling it to learn complex patterns from the data. The number of hidden layers and the number of neurons in each layer are crucial hyperparameters that significantly impact the model&rsquo;s performance.</p>
<h4 id="315-the-output-layer">3.1.5 The Output Layer</h4>
<p>The output layer of the neural network produces the final predictions or outputs. The number of neurons in the output layer depends on the nature of the task. For example, in binary classification problems, there is usually one neuron for a single output representing the probability of belonging to one class. In multi-class classification problems, there are multiple neurons, each corresponding to a class, and the highest activation value determines the predicted class label. In regression tasks, the output layer might have a single neuron to predict a continuous value.</p>
<h3 id="32-defining-the-neural-network-model-class-in-code">3.2 Defining the Neural Network Model Class in Code</h3>
<p>Now that we have discussed the fundamental components of the Neural Network Model class, let&rsquo;s proceed with the code implementation. We will define each part of the class and explain its significance along the way.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">NeuralNetworkModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">NeuralNetworkModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_sizes</span> <span class="o">=</span> <span class="n">hidden_sizes</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Create the layers for the neural network</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Define the forward pass through the neural network</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">x</span>
</span></span></code></pre></div><h4 id="explanation">Explanation:</h4>
<ol>
<li>
<p>We start by importing the required libraries: <code>torch</code>, <code>torch.nn</code>, and <code>torch.nn.functional</code>. These libraries contain essential tools for building and training neural networks in PyTorch.</p>
</li>
<li>
<p>We define the <code>NeuralNetworkModel</code> class and inherit from <code>nn.Module</code>, which is the base class for all PyTorch models. By inheriting from <code>nn.Module</code>, our class gains several functionalities, including the ability to hold parameters, manage sub-modules, and perform backpropagation efficiently.</p>
</li>
<li>
<p>In the <code>__init__</code> method, we specify the constructor of the class. It takes three arguments:</p>
<ul>
<li><code>input_size</code>: The number of features in the input data, which determines the number of neurons in the input layer.</li>
<li><code>hidden_sizes</code>: A list that specifies the number of neurons in each hidden layer. The length of this list determines the number of hidden layers in the network.</li>
<li><code>output_size</code>: The number of neurons in the output layer, which is determined by the task (e.g., binary classification, multi-class classification, regression).</li>
</ul>
</li>
<li>
<p>We call the <code>__init__</code> method of the parent class (<code>nn.Module</code>) using <code>super(NeuralNetworkModel, self).__init__()</code> to properly initialize the <code>nn.Module</code> functionalities.</p>
</li>
<li>
<p>Next, we create the layers for our neural network:</p>
<ul>
<li><code>self.input_layer</code>: This is the input layer, created using <code>nn.Linear(self.input_size, self.hidden_sizes[0])</code>. It connects the input data to the first hidden layer and performs a linear transformation.</li>
<li><code>self.hidden_layers</code>: This is a list of hidden layers, created using a list comprehension. Each hidden layer is an instance of <code>nn.Linear</code> and is initialized</li>
</ul>
</li>
</ol>
<p>with the number of neurons specified in the <code>hidden_sizes</code> list.</p>
<ul>
<li><code>self.output_layer</code>: This is the output layer, created using <code>nn.Linear(self.hidden_sizes[-1], self.output_size)</code>. It connects the last hidden layer to the output data and performs a linear transformation.</li>
</ul>
<ol start="6">
<li>
<p>In the <code>forward</code> method, we define the forward pass of the neural network. It takes an input <code>x</code> and applies the layers in sequence:</p>
<ul>
<li><code>x = F.relu(self.input_layer(x))</code>: The input data <code>x</code> passes through the input layer, and the ReLU activation function (<code>F.relu</code>) is applied. ReLU introduces non-linearity to the model, allowing it to learn complex patterns from the data.</li>
<li><code>for layer in self.hidden_layers:</code>: We use a loop to sequentially pass the data through each hidden layer.</li>
<li><code>x = F.relu(layer(x))</code>: At each hidden layer, we apply the ReLU activation function again.</li>
<li><code>x = self.output_layer(x)</code>: Finally, the data flows through the output layer to produce the final predictions.</li>
</ul>
</li>
<li>
<p>The method returns the output <code>x</code>, which contains the predictions made by the neural network.</p>
</li>
</ol>
<h3 id="33-summary">3.3 Summary</h3>
<p>In this extensive section, we have learned how to define the Neural Network Model class in PyTorch comprehensively. We discussed the essential components of the class, such as the constructor method, the forward method, the input layer, the hidden layers, and the output layer.</p>
<p>Understanding the intricacies of defining a neural network class is a critical step in mastering deep learning with PyTorch. By customizing the architecture and layers of the class, you can build powerful and versatile neural network models for various machine learning tasks.</p>
<p>In the next sections, we will delve into backpropagation, optimization, activation functions, loss functions, training loops, and more, further enhancing our knowledge of deep learning with PyTorch.</p>
<p>Keep up the excellent work, and let&rsquo;s continue our exciting journey into the world of neural networks! 🚀🧠</p>
<h2 id="4-implementing-forward-propagation">4. Implementing Forward Propagation</h2>
<p>The <code>forward</code> method is the heart of the neural network class. It defines the forward pass, where input data moves through the network to produce predictions.</p>
<p>For our neural network class, the forward pass involves passing the input data through the input layer, applying ReLU activation to the hidden layers, and then passing through the output layer.</p>
<h2 id="5-backpropagation-and-training">5. Backpropagation and Training</h2>
<p>To train a neural network, we need to perform backpropagation. It is the process of computing gradients and updating weights and biases to minimize the defined loss function.</p>
<p>We use an optimizer, such as <code>torch.optim.SGD</code> or <code>torch.optim.Adam</code>, to update the parameters of the model during training.</p>
<h2 id="6-adding-activation-functions">6. Adding Activation Functions</h2>
<p>Activation functions introduce non-linearity to the model, allowing it to learn complex patterns from the data. In our neural network class, we use the Rectified Linear Unit (ReLU) activation function for the hidden layers. However, PyTorch provides various activation functions, and you can experiment with them based on your specific problem.</p>
<h2 id="7-customizing-loss-functions">7. Customizing Loss Functions</h2>
<p>The choice of loss function depends on the task at hand. For example, for binary classification problems, we often use Binary Cross Entropy Loss, while for multi-class classification, we use Cross Entropy Loss. For regression tasks, Mean Squared Error (MSE) is a common choice. You can customize the loss function in the training process based on your specific needs.</p>
<h2 id="8-optimizers-for-training">8. Optimizers for Training</h2>
<p>PyTorch provides various optimizers like Stochastic Gradient Descent (SGD), Adam, RMSprop, etc. The optimizer updates the model&rsquo;s parameters during backpropagation to minimize the loss function.</p>
<h2 id="9-putting-it-all-together-example-usage">9. Putting It All Together: Example Usage</h2>
<p>Now, let&rsquo;s put all the pieces together and see how to use our custom <code>NeuralNetworkModel</code> class for a specific task.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Example usage of the NeuralNetworkModel class</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Assuming we have a dataset with 10 input features and want to predict 3 classes</span>
</span></span><span class="line"><span class="cl"><span class="n">input_size</span> <span class="o">=</span> <span class="mi">10</span>
</span></span><span class="line"><span class="cl"><span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>  <span class="c1"># Two hidden layers with 64 and 32 neurons, respectively</span>
</span></span><span class="line"><span class="cl"><span class="n">output_size</span> <span class="o">=</span> <span class="mi">3</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Create an instance of the NeuralNetworkModel class</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">NeuralNetworkModel</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Define the loss function and optimizer</span>
</span></span><span class="line"><span class="cl"><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Training loop</span>
</span></span><span class="line"><span class="cl"><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Forward pass</span>
</span></span><span class="line"><span class="cl">    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">target_labels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Backward pass and optimization</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Print the loss at</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> <span class="n">certain</span> <span class="n">intervals</span> <span class="n">to</span> <span class="n">monitor</span> <span class="n">training</span> <span class="n">progress</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Epoch [</span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">], Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># After training, you can use the model for predictions</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_input_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Predictions:&#34;</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="10-conclusion">10. Conclusion</h2>
<p>Congratulations! You have successfully implemented a comprehensive Neural Network Model class using PyTorch. We covered the fundamental building blocks of neural networks, the steps involved in building the model class, and how to use it for training and prediction.</p>
<p>By understanding this tutorial, you now have a solid foundation to explore and experiment with more complex neural network architectures and tackle various machine learning tasks using PyTorch.</p>
<p>Remember, practice is key to mastering the art of deep learning. Keep experimenting, learning, and building exciting projects. 🚀</p>
<p>Happy coding! 😊🎓</p>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/pytorch/">PyTorch</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-NN-Class%2F&amp;text=PyTorch&#43;Tutorial%3A&#43;Implementing&#43;a&#43;Neural&#43;Network&#43;Class" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-NN-Class%2F&amp;t=PyTorch&#43;Tutorial%3A&#43;Implementing&#43;a&#43;Neural&#43;Network&#43;Class" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=PyTorch%20Tutorial%3A%20Implementing%20a%20Neural%20Network%20Class&amp;body=https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-NN-Class%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-NN-Class%2F&amp;title=PyTorch&#43;Tutorial%3A&#43;Implementing&#43;a&#43;Neural&#43;Network&#43;Class" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=PyTorch&#43;Tutorial%3A&#43;Implementing&#43;a&#43;Neural&#43;Network&#43;Class%20https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-NN-Class%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Farmanasq.github.io%2FDeep-Learning%2FPyTorch-NN-Class%2F&amp;title=PyTorch&#43;Tutorial%3A&#43;Implementing&#43;a&#43;Neural&#43;Network&#43;Class" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://armanasq.github.io/"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu423262b037e945bf3d00a3d75617f940_247637_270x270_fill_q75_lanczos_center.jpeg" alt="Arman Asgharpoor Golroudbari"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://armanasq.github.io/">Arman Asgharpoor Golroudbari</a></h5>
      <h6 class="card-subtitle">Space-AI Researcher</h6>
      <p class="card-text">My research interests revolve around planetary rovers and spacecraft vision-based navigation.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-comment-alt"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:a.asgharpoor1993@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=IlAgF9UAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/armanasq" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://linkedin.com/in/asgharpoor" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://orcid.org/my-orcid?orcid=0000-0001-6271-4533" target="_blank" rel="noopener">
        <i class="ai ai-orcid"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://www.webofscience.com/wos/author/record/IAN-3152-2023" target="_blank" rel="noopener">
        <i class="ai ai-publons"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://researchgate.net/profile/Arman_Asgharpoor" target="_blank" rel="noopener">
        <i class="ai ai-researchgate"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/uploads/cv.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>









  
  
  

  

  
  <section id="comments">
    
  
  <script src="https://giscus.app/client.js"
          data-repo="Armanasq/Armanasq.github.io"
          data-repo-id="R_kgDOJi13ZQ"
          data-category="[ENTER CATEGORY NAME HERE]"
          data-category-id="[ENTER CATEGORY ID HERE]"
          data-mapping="pathname"
          data-strict="0"
          data-reactions-enabled="1"
          data-emit-metadata="0"
          data-input-position="top"
          data-theme="preferred_color_scheme"
          data-lang="en"
          data-loading="lazy"
          crossorigin="anonymous"
          async>
  </script>


  </section>
  










  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2024 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js"></script>




  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.85070d5fe00d43eaedff44310b81dc2c.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>













  
    
      
      <!DOCTYPE html>
<html>
<head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-55GQYC5GYC"></script>

<style>
  .myImg {
    border-radius: 5px;
    cursor: pointer;
    transition: 0.3s;
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  .myImg:hover {
    opacity: 0.7;
    cursor: pointer;
  }

   
  .modal-img {
    display: none;  
    position: fixed;  
    z-index: 1;  
    padding-top: 150px;  
    left: 0;
    top: 0px;
    width: 100%;  
    height: 100%;  
    overflow: visible;  
    background-color: rgb(0, 0, 0);  
    background-color: rgba(0, 0, 0, 0.6);  
    margin-left: auto;
    margin-right: auto;
  }

   
  .modal-content {
    display: block;
    margin-left: auto;
    margin-right: auto;
    max-width: 80%;
    max-height: 80%;

  }

   
  #caption {
    margin-left: auto;
    margin-right: auto;
    width: 80%;
    max-width: 700px;
    text-align: center;
    padding: 10px 0;

  }

   
  .modal-content,
  #caption {
    -webkit-animation-name: zoom;
    -webkit-animation-duration: 0.6s;
    animation-name: zoom;
    animation-duration: 0.6s;
    margin-left: auto;
    margin-right: auto;
  }

  @-webkit-keyframes zoom {
    from {
      -webkit-transform: scale(0);
    }
    to {
      -webkit-transform: scale(1);
    }
  }

  @keyframes zoom {
    from {
      transform: scale(0);
    }
    to {
      transform: scale(1);
    }
  }

   
  
 .modal-close {
    position: absolute;
    top: -55px;
    right: 0;
    font-size: 40px;
    font-weight: bold;
    transition: 0.3s;
    cursor: pointer;
  }

  .modal-close:hover,
  .modal-close:focus {
    color: #bbb;
    text-decoration: none;
  }

   
  @media only screen and (max-width: 900px) {
    .modal-content {
      width: 90%;
    }
  }

  .test:hover {
    scale: 1.2;
  }







  .navbar-nav {
    font-size:20px;
    font-family: Merriweather,sans-serif;
  }

  .robotic-section-container {
    display: flex;
    flex-wrap: wrap;
    justify-content: space-between;
    max-width: 1200px;
    margin: 0 auto;
  }
  
  .robotic-section {
    flex-basis: calc(30.33% - 12px);
    margin: 10px;
    background-color: #fff;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    border-radius: 8px;
    transition: box-shadow 0.3s ease-in-out;
    overflow: hidden;
  }
  
  .robotic-section:hover {
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
  }
  
  .robotic-section-content {
    text-align: center;
    padding: 20px;
    display: flex;
    flex-direction: column;
    justify-content: space-between;
    height: 100%;
  }
  
  .robotic-section-content .image-placeholder {
    width: 300px;
    height: 300px;
    margin: 0 auto;
    display: flex;
    align-items: center;
    justify-content: center;
    background-color: #f1f1f1;
  }
  
  .robotic-section-content .image-placeholder img {
    max-width: 100%;
    max-height: 100%;
    object-fit: contain;
  }
  
  .robotic-section-content-h2 {
    margin-top: 10px;
    font-size: 1.rem;
    font-weight: bold;
    color: #333;
  }
  
  .robotic-section-content-h2 :hover{
    font-size: 10px
  }
  .robotic-section-content-h2 {
    margin-top: 10px;
    color: #777;
    font-size: 1.2rem;
  }
  
  .robotic-section-content .text-placeholder {
    height: 80px;
    background-color: #f1f1f1;
  }
  
  .robotic-section-content a {
    display: inline-block;
    margin-top: 20px;
    padding: 10px 20px;
    background-color: #FF4081;
    color: #fff;
    text-decoration: none;
    border-radius: 4px;
    font-weight: bold;
    transition: background-color 0.3s ease-in-out;
  }
  
  .robotic-section-content a:hover {
    background-color: #E91E63;
  }
  
   
  @media (max-width: 768px) {
    .robotic-section {
      flex-basis: calc(50% - 40px);
    }
  }
  
   
  @media (max-width: 480px) {
    .robotic-section {
      flex-basis: 100%;
    }
  }
</style>
</head>
<body>

<div id="myModal" class="modal-img">
  <div class="modal-content">
    <span class="modal-close">&times;</span>
    <img id="img01" style="margin-left: auto; margin-right: auto;">
    <div id="caption"></div>
  </div>
</div>




<script>
    
    var modal = document.getElementById("myModal");
    
    
    var images = document.querySelectorAll("img.myImg");
    
    
    var modalImg = document.getElementById("img01");
    var captionText = document.getElementById("caption");
    
    
    for (var i = 0; i < images.length; i++) {
      
      images[i].setAttribute("data-src", images[i].src);
      
      images[i].addEventListener("click", function() {
        
        modalImg.src = this.getAttribute("data-src");
        captionText.innerHTML = this.alt;
        
        modal.style.display = "block";
      });
    }
    
    
    var modalClose = document.querySelector(".modal-content .modal-close");
    
    
    modalClose.onclick = function() {
      modal.style.display = "none";
    };
    
















    
    </script>
    
    </body>
    </html>
      
    
  






</body>
</html>
